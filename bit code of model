{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17LGYYYEYnOjWArHXvKIhNkzV9-nc8EFd","timestamp":1762086829385}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"XCcc7ubR3YeS","executionInfo":{"status":"error","timestamp":1762087102705,"user_tz":-330,"elapsed":144615,"user":{"displayName":"sharad pratap","userId":"06768833311320204192"}},"outputId":"3fced9bc-a722-4d5a-b254-999db19d882e","colab":{"base_uri":"https://localhost:8080/","height":1000}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.10.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.28.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.51.0\n"]},{"output_type":"error","ename":"ValueError","evalue":"mount failed","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1441867529.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Corrected file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["# Importing required libraries\n","!pip install streamlit\n","\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Input, LSTM, Dense\n","import plotly.graph_objects as go\n","# ---------------- Data Collection & Preprocessing ----------------\n","\n","# Load dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Corrected file path\n","data_path = \"/content/drive/MyDrive/Expanded_Rainfall_Dataset.csv\"\n","pdf = pd.read_csv(data_path)\n","\n","# Convert to DataFrame\n","pdf = pd.DataFrame(pdf)\n","print(\"Dataset loaded successfully.\\n\")\n","\n","# Display initial rows\n","print(pdf.head(), \"\\n\")\n","print(pdf.tail(), \"\\n\")\n","\n","# Check if dataset is empty\n","if pdf.empty:\n","    raise ValueError(\"Dataset is empty. Please check the file path and content.\")\n","\n","# Check for missing values\n","print(\"Missing values before cleaning:\\n\", pdf.isnull().sum(), \"\\n\")\n"," #Data Preprocessing\n","\n","# Convert 'date' column to datetime\n","if 'date' in pdf.columns:\n","    pdf['date'] = pd.to_datetime(pdf['date'], errors='coerce')  # Convert invalid dates to NaT\n","    pdf.dropna(subset=['date'], inplace=True)  # Remove rows with invalid dates\n","    pdf.set_index('date', inplace=True)  # Set date as index\n","else:\n","     raise KeyError(\"Column 'date' not found in the dataset.\")\n","\n","# Ensure the index is datetime before resampling\n","if not isinstance(pdf.index, pd.DatetimeIndex):\n","    raise TypeError(\"Index is not a DatetimeIndex. Check data conversion.\")\n","\n","# Resample to daily frequency and take the mean\n","pdf = pdf.resample(\"D\").mean()\n","\n","# Handle missing values\n","pdf[\"winddirection\"] = pdf[\"winddirection\"].fillna(pdf[\"winddirection\"].mode()[0])\n","pdf[\"windspeed\"] = pdf[\"windspeed\"].fillna(pdf[\"windspeed\"].median())\n","\n","# Remove duplicate index values (important for time series)\n","pdf = pdf[~pdf.index.duplicated(keep=\"first\")]\n","\n","if pdf['rainfall'].dtype == object:\n","    pdf['rainfall'].replace({'yes': 1, 'no': 0}, inplace=True)\n","\n","# Convert all data to numeric (coerce errors to NaN)\n","pdf = pdf.apply(pd.to_numeric, errors='coerce')\n","\n","# Drop or fill NaN values\n","pdf.dropna(inplace=True)\n","\n","# Resample data to daily frequency and take mean\n","pdf = pdf.resample(\"D\").mean()\n","\n","# Display data summary\n","print(\"\\nData Summary:\")\n","print(pdf.info(), \"\\n\")\n","print(pdf.describe(), \"\\n\")\n","# Handle missing values\n","pdf[\"winddirection\"] = pdf[\"winddirection\"].fillna(pdf[\"winddirection\"].mode()[0])\n","pdf[\"windspeed\"] = pdf[\"windspeed\"].fillna(pdf[\"windspeed\"].median())\n","print(pdf.isnull().sum())\n","# Remove duplicate index values (important for time series)\n","pdf = pdf[~pdf.index.duplicated(keep=\"first\")]\n","\n","if pdf['rainfall'].dtype == object:\n","    pdf['rainfall'].replace({'yes': 1, 'no': 0}, inplace=True)\n","\n","# Convert all data to numeric (coerce errors to NaN)\n","pdf = pdf.apply(pd.to_numeric, errors='coerce')\n","\n","# Drop or fill NaN values\n","pdf.dropna(inplace=True)\n","\n","# Resample data to daily frequency and take mean\n","pdf = pdf.resample(\"D\").mean()\n","\n","# Display data summary\n","print(\"\\nData Summary:\")\n","print(pdf.info(), \"\\n\")\n","print(pdf.describe(), \"\\n\")\n","# Ensure 'date' column exists and is datetime\n","if \"date\" in pdf.columns:\n","    pdf[\"date\"] = pd.to_datetime(pdf[\"date\"])\n","    pdf.set_index(\"date\", inplace=True)\n","else:\n","    st.error(\"ğŸš« The dataset must contain a 'date' column for time-based features.\")\n","    st.stop()\n","# ---------------- Feature Engineering (Optimized for LSTM) ----------------\n","\n","# Lag Features - capturing past influence\n","pdf[\"rainfall_lag_1\"] = pdf[\"rainfall\"].shift(1)\n","pdf[\"rainfall_lag_3\"] = pdf[\"rainfall\"].shift(3)\n","pdf[\"rainfall_lag_7\"] = pdf[\"rainfall\"].shift(7)\n","pdf[\"humidity_lag_1\"] = pdf[\"humidity\"].shift(1)\n","pdf[\"windspeed_lag_1\"] = pdf[\"windspeed\"].shift(1)\n","pdf[\"temparature_lag_1\"] = pdf[\"temparature\"].shift(1)\n","\n","# Rolling Window Averages - smoothing recent trends\n","pdf[\"rainfall_rolling_3\"] = pdf[\"rainfall\"].rolling(window=3).mean()\n","pdf[\"humidity_rolling_3\"] = pdf[\"humidity\"].rolling(window=3).mean()\n","pdf[\"cloud_rolling_3\"] = pdf[\"cloud\"].rolling(window=3).mean()\n","\n","# Date Features - capturing seasonal patterns\n","pdf[\"month\"] = pdf.index.month\n","pdf[\"dayofweek\"] = pdf.index.dayofweek\n","\n","# Drop NaN rows caused by shifting/rolling\n","pdf.dropna(inplace=True)\n","# ---------------- Train-Test Split ----------------\n","\n","# Define features and target (based on updated feature engineering)\n","features = [\n","    \"rainfall_lag_1\", \"rainfall_lag_3\", \"rainfall_lag_7\",\n","    \"humidity_lag_1\", \"windspeed_lag_1\", \"temparature_lag_1\",\n","    \"rainfall_rolling_3\", \"humidity_rolling_3\", \"cloud_rolling_3\",\n","    \"month\", \"dayofweek\"\n","]\n","target = \"rainfall\"\n","\n","# Ensure all features and target exist in the DataFrame\n","missing_cols = [col for col in features + [target] if col not in pdf.columns]\n","if missing_cols:\n","    raise KeyError(f\"The following required columns are missing: {missing_cols}\")\n","\n","# Feature Matrix (X) and Target Vector (y)\n","X = pdf[features]\n","y = pdf[target]\n","\n","# Initialize MinMaxScaler for features and target\n","feature_scaler = MinMaxScaler()\n","target_scaler = MinMaxScaler()\n","\n","# Scale the features and target\n","X_scaled = feature_scaler.fit_transform(X)\n","y_scaled = target_scaler.fit_transform(y.values.reshape(-1, 1))\n","\n","# Train-test split (50% test size, no shuffling for time series)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y_scaled, test_size=0.5, shuffle=False\n",")\n","\n","# Check train/test sizes\n","if len(X_train) > 0 and len(X_test) > 0:\n","    print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n","else:\n","    raise ValueError(\"Train or test set is empty. Check data or split ratio.\")\n","# ---------------- LSTM Model Training ----------------\n","\n","# Import TensorBoard\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","# Create a TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n","# ---------------- LSTM Model Training ----------------\n","\n","# Import TensorBoard\n","from tensorflow.keras.callbacks import TensorBoard\n","\n","# Create a TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n","\n","# ---------------- LSTM Model Training ----------------\n","\n","# Reshape for LSTM\n","X_train_lstm = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_test_lstm = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","\n","# Build LSTM Model\n","model = Sequential([\n","    Input(shape=(X_train_lstm.shape[1], 1)),  # Define input explicitly\n","    LSTM(100, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(100, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(50, return_sequences=False),\n","    Dropout(0.2),\n","    Dense(25, activation='relu'),\n","    Dense(1)\n","])\n","\n","# Compile Model\n","model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n","\n","# Train Model\n","print(\"\\nTraining LSTM Model...\")\n","history = model.fit(X_train_lstm, y_train, batch_size=16, epochs=10, verbose=1)\n","model.save(\"rainfall_lstm_model.h5\")\n","\n","# ---------------- Predictions & Evaluation ----------------\n","# Make predictions\n","y_pred_lstm = model.predict(X_test_lstm)\n","\n","# Inverse transform predictions\n","y_pred_lstm = target_scaler.inverse_transform(y_pred_lstm.reshape(-1, 1)).flatten()\n","y_test_inv = target_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n","\n","# Calculate errors\n","mae_lstm = mean_absolute_error(y_test_inv, y_pred_lstm)\n","mse_lstm = mean_squared_error(y_test_inv, y_pred_lstm)\n","r2 = r2_score(y_test_inv, y_pred_lstm)  # RÂ² Score Calculation\n","\n","# MAPE-based accuracy (Avoid division by zero)\n","non_zero_indices = y_test_inv != 0  # Mask to exclude zero values\n","if np.sum(non_zero_indices) > 0:  # Ensure at least one valid value\n","    mape = np.mean(np.abs((y_test_inv[non_zero_indices] - y_pred_lstm[non_zero_indices]) / y_test_inv[non_zero_indices])) * 100\n","    accuracy = 100 - mape\n","else:\n","    mape = None\n","    accuracy = None  # No valid accuracy can be calculated\n","\n","print(f\"\\nLSTM Model Performance:\")\n","print(f\"MAE: {mae_lstm:.4f}\")\n","print(f\"MSE: {mse_lstm:.4f}\")\n","print(f\"RÂ² Score: {r2:.4f}\")\n","if accuracy is not None:\n","    print(f\"Regression Accuracy: {accuracy:.2f}%\")\n","else:\n","    print(\"Regression Accuracy: Cannot be computed (division by zero issue)\")\n","\n","# ---------------- Visualization ---------------\n","# Sample Data (20 Days of Rainfall)\n","time_steps = np.arange(1, 21)  # Time (Days)\n","actual_rainfall = np.random.randint(0, 50, size=20)  # Random Actual Rainfall (0-50mm)\n","predicted_rainfall = actual_rainfall + np.random.randint(-5, 5, size=20)  # Prediction with slight variation\n","\n","# Define colors based on rainfall intensity\n","def get_color(val):\n","    if val == 0:\n","        return \"blue\"  # No Rain\n","    elif val <= 10:\n","        return \"green\"  # Light Rain\n","    elif val <= 30:\n","        return \"yellow\"  # Moderate Rain\n","    else:\n","        return \"red\"  # Heavy Rain\n","\n","colors = [get_color(val) for val in actual_rainfall]\n","\n","# Create the Figure\n","fig = go.Figure()\n","\n","# Add Actual Rainfall as a Bar Chart\n","fig.add_trace(go.Bar(\n","    x=time_steps,\n","    y=actual_rainfall,\n","    name=\"Actual Rainfall\",\n","    marker_color=colors,\n","    visible=True  # Visible by default\n","))\n","\n","# Add Predicted Rainfall as a Line Chart\n","fig.add_trace(go.Scatter(\n","    x=time_steps,\n","    y=predicted_rainfall,\n","    mode=\"lines+markers\",\n","    name=\"Predicted Rainfall\",\n","    line=dict(color=\"black\", dash=\"dash\"),\n","    visible=True  # Visible by default\n","))\n","\n","# Customize Layout\n","fig.update_layout(\n","    title=\"Rainfall Prediction using LSTM (Interactive)\",\n","    xaxis_title=\"Time (Days)\",\n","    yaxis_title=\"Rainfall (mm)\",\n","    legend_title=\"Select Data\",\n","    template=\"plotly_white\"\n",")\n","\n","# Show Interactive Plot\n","fig.show()\n","\n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"dPEIDcOc86YN"}}]}